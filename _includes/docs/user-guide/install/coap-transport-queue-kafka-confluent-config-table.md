<table>
  <thead>
      <tr>
          <td style="width: 25%"><b>Parameter</b></td><td style="width: 30%"><b>Environment Variable</b></td><td style="width: 15%"><b>Default Value</b></td><td style="width: 30%"><b>Description</b></td>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>queue.kafka.bootstrap.servers</td>
          <td>TB_KAFKA_SERVERS</td>
          <td>localhost:9092</td>
          <td>Kafka Bootstrap Servers</td>
      </tr>
      <tr>
          <td>queue.kafka.ssl.enabled</td>
          <td>TB_KAFKA_SSL_ENABLED</td>
          <td>false</td>
          <td>Enable/Disable SSL Kafka communication</td>
      </tr>
      <tr>
          <td>queue.kafka.ssl.truststore.location</td>
          <td>TB_KAFKA_SSL_TRUSTSTORE_LOCATION</td>
          <td></td>
          <td>The location of the trust store file</td>
      </tr>
      <tr>
          <td>queue.kafka.ssl.truststore.password</td>
          <td>TB_KAFKA_SSL_TRUSTSTORE_PASSWORD</td>
          <td></td>
          <td>The password of trust store file if specified</td>
      </tr>
      <tr>
          <td>queue.kafka.ssl.keystore.location</td>
          <td>TB_KAFKA_SSL_KEYSTORE_LOCATION</td>
          <td></td>
          <td>The location of the key store file. This is optional for client and can be used for two-way authentication for client</td>
      </tr>
      <tr>
          <td>queue.kafka.ssl.keystore.password</td>
          <td>TB_KAFKA_SSL_KEYSTORE_PASSWORD</td>
          <td></td>
          <td>The store password for the key store file. This is optional for client and only needed if ‘ssl.keystore.location’ is configured. Key store password is not supported for PEM format</td>
      </tr>
      <tr>
          <td>queue.kafka.ssl.key.password</td>
          <td>TB_KAFKA_SSL_KEY_PASSWORD</td>
          <td></td>
          <td>The password of the private key in the key store file or the PEM key specified in ‘keystore.key’</td>
      </tr>
      <tr>
          <td>queue.kafka.acks</td>
          <td>TB_KAFKA_ACKS</td>
          <td>all</td>
          <td>The number of acknowledgments the producer requires the leader to have received before considering a request complete. This controls the durability of records that are sent. The following settings are allowed:0,1 and all</td>
      </tr>
      <tr>
          <td>queue.kafka.retries</td>
          <td>TB_KAFKA_RETRIES</td>
          <td>1</td>
          <td>Number of retries. Resend any record whose send fails with a potentially transient error</td>
      </tr>
      <tr>
          <td>queue.kafka.compression.type</td>
          <td>TB_KAFKA_COMPRESSION_TYPE</td>
          <td>none</td>
          <td>The compression type for all data generated by the producer. The default is none (i.e. no compression). Valid values none or gzip</td>
      </tr>
      <tr>
          <td>queue.kafka.batch.size</td>
          <td>TB_KAFKA_BATCH_SIZE</td>
          <td>16384</td>
          <td>Default batch size. This setting gives the upper bound of the batch size to be sent</td>
      </tr>
      <tr>
          <td>queue.kafka.linger.ms</td>
          <td>TB_KAFKA_LINGER_MS</td>
          <td>1</td>
          <td>This variable creates a small amount of artificial delay—that is, rather than immediately sending out a record</td>
      </tr>
      <tr>
          <td>queue.kafka.max.request.size</td>
          <td>TB_KAFKA_MAX_REQUEST_SIZE</td>
          <td>1048576</td>
          <td>The maximum size of a request in bytes. This setting will limit the number of record batches the producer will send in a single request to avoid sending huge requests</td>
      </tr>
      <tr>
          <td>queue.kafka.max.in.flight.requests.per.connection</td>
          <td>TB_KAFKA_MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION</td>
          <td>5</td>
          <td>The maximum number of unacknowledged requests the client will send on a single connection before blocking</td>
      </tr>
      <tr>
          <td>queue.kafka.buffer.memory</td>
          <td>TB_BUFFER_MEMORY</td>
          <td>33554432</td>
          <td>The total bytes of memory the producer can use to buffer records waiting to be sent to the server</td>
      </tr>
      <tr>
          <td>queue.kafka.replication_factor</td>
          <td>TB_QUEUE_KAFKA_REPLICATION_FACTOR</td>
          <td>1</td>
          <td>The multiple copies of data over the multiple brokers of Kafka</td>
      </tr>
      <tr>
          <td>queue.kafka.max_poll_interval_ms</td>
          <td>TB_QUEUE_KAFKA_MAX_POLL_INTERVAL_MS</td>
          <td>300000</td>
          <td>The maximum delay between invocations of poll() when using consumer group management. This places an upper bound on the amount of time that the consumer can be idle before fetching more records</td>
      </tr>
      <tr>
          <td>queue.kafka.max_poll_records</td>
          <td>TB_QUEUE_KAFKA_MAX_POLL_RECORDS</td>
          <td>8192</td>
          <td>The maximum number of records returned in a single call to poll()</td>
      </tr>
      <tr>
          <td>queue.kafka.max_partition_fetch_bytes</td>
          <td>TB_QUEUE_KAFKA_MAX_PARTITION_FETCH_BYTES</td>
          <td>16777216</td>
          <td>The maximum amount of data per-partition the server will return. Records are fetched in batches by the consumer</td>
      </tr>
      <tr>
          <td>queue.kafka.fetch_max_bytes</td>
          <td>TB_QUEUE_KAFKA_FETCH_MAX_BYTES</td>
          <td>134217728</td>
          <td>The maximum amount of data the server will return. Records are fetched in batches by the consumer</td>
      </tr>
      <tr>
          <td>queue.kafka.request.timeout.ms</td>
          <td>TB_QUEUE_KAFKA_REQUEST_TIMEOUT_MS</td>
          <td>30000</td>
          <td>The configuration controls the maximum amount of time the client will wait for the response of a request. By default, set 30 seconds</td>
      </tr>
      <tr>
          <td>queue.kafka.session.timeout.ms</td>
          <td>TB_QUEUE_KAFKA_SESSION_TIMEOUT_MS</td>
          <td>10000</td>
          <td>The timeout used to detect client failures when using Kafka’s group management facility. The client sends periodic heartbeats to indicate its liveness to the broker. By default, set 10 seconds</td>
      </tr>
      <tr>
          <td>queue.kafka.use_confluent_cloud</td>
          <td>TB_QUEUE_KAFKA_USE_CONFLUENT_CLOUD</td>
          <td>false</td>
          <td>Enable/Disable using of Confluent Cloud</td>
      </tr>
      <tr>
          <td>queue.kafka.confluent.ssl.algorithm</td>
          <td>TB_QUEUE_KAFKA_CONFLUENT_SSL_ALGORITHM</td>
          <td>https</td>
          <td>The endpoint identification algorithm used by clients to validate server host name. The default value is https</td>
      </tr>
      <tr>
          <td>queue.kafka.confluent.sasl.mechanism</td>
          <td>TB_QUEUE_KAFKA_CONFLUENT_SASL_MECHANISM</td>
          <td>PLAIN</td>
          <td>The mechanism used to authenticate Schema Registry requests. SASL/PLAIN should only be used with TLS/SSL as transport layer to ensure that clear passwords are not transmitted on the wire without encryption</td>
      </tr>
      <tr>
          <td>queue.kafka.confluent.sasl.config</td>
          <td>TB_QUEUE_KAFKA_CONFLUENT_SASL_JAAS_CONFIG</td>
          <td>org.apache.kafka.common.security.plain.PlainLoginModule required username="CLUSTER_API_KEY" password="CLUSTER_API_SECRET";</td>
          <td>Using JAAS Configuration for specifying multiple SASL mechanisms on a broker</td>
      </tr>
      <tr>
          <td>queue.kafka.confluent.security.protocol</td>
          <td>TB_QUEUE_KAFKA_CONFLUENT_SECURITY_PROTOCOL</td>
          <td>SASL_SSL</td>
          <td>Protocol used to communicate with brokers. Valid values are: PLAINTEXT, SSL, SASL_PLAINTEXT, SASL_SSL</td>
      </tr>
      <tr>
          <td>queue.kafka.other-inline</td>
          <td>TB_QUEUE_KAFKA_OTHER_PROPERTIES</td>
          <td></td>
          <td>In this section you can specify custom parameters (semicolon separated) for Kafka consumer/producer/admin # Example "metrics.recording.level:INFO;metrics.sample.window.ms:30000"</td>
      </tr>
      <tr>
          <td>queue.kafka.other</td>
          <td></td>
          <td></td>
          <td>DEPRECATED. In this section you can specify custom parameters for Kafka consumer/producer and expose the env variables to configure outside</td>
      </tr>
      <tr>
          <td>queue.kafka.topic-properties.rule-engine</td>
          <td>TB_QUEUE_KAFKA_RE_TOPIC_PROPERTIES</td>
          <td>retention.ms:604800000;segment.bytes:26214400;retention.bytes:1048576000;partitions:1;min.insync.replicas:1</td>
          <td>Kafka properties for Rule Engine topic</td>
      </tr>
      <tr>
          <td>queue.kafka.topic-properties.core</td>
          <td>TB_QUEUE_KAFKA_CORE_TOPIC_PROPERTIES</td>
          <td>retention.ms:604800000;segment.bytes:26214400;retention.bytes:1048576000;partitions:1;min.insync.replicas:1</td>
          <td>Kafka properties for Core topic</td>
      </tr>
      <tr>
          <td>queue.kafka.topic-properties.transport-api</td>
          <td>TB_QUEUE_KAFKA_TA_TOPIC_PROPERTIES</td>
          <td>retention.ms:604800000;segment.bytes:26214400;retention.bytes:1048576000;partitions:10;min.insync.replicas:1</td>
          <td>Kafka properties for Transport API topic</td>
      </tr>
      <tr>
          <td>queue.kafka.topic-properties.notifications</td>
          <td>TB_QUEUE_KAFKA_NOTIFICATIONS_TOPIC_PROPERTIES</td>
          <td>retention.ms:604800000;segment.bytes:26214400;retention.bytes:1048576000;partitions:1;min.insync.replicas:1</td>
          <td>Kafka properties for Notification topic</td>
      </tr>
      <tr>
          <td>queue.kafka.auto_offset_reset</td>
          <td>TB_QUEUE_KAFKA_AUTO_OFFSET_RESET</td>
          <td>earliest</td>
          <td>Could be earliest, latest or none</td>
      </tr>
  </tbody>
</table>